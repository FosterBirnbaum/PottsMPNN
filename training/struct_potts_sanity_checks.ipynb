{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PottsMPNN sanity checks\n",
        "\n",
        "This notebook provides quick smoke tests for the Potts/structure losses and optional ESM + FAPE components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from training.struct_potts_losses import (\n",
        "    msa_similarity_loss,\n",
        "    msa_similarity_loss_esm,\n",
        "    structure_consistency_loss,\n",
        "    structure_fape_loss,\n",
        ")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "B, L, V, M = 2, 8, 22, 4\n",
        "log_probs = torch.log_softmax(torch.randn(B, L, V), dim=-1)\n",
        "msa_tokens = torch.randint(0, V, (B, M, L))\n",
        "msa_mask = torch.ones(B, M, L)\n",
        "seq_mask = torch.ones(B, L)\n",
        "\n",
        "baseline_loss = msa_similarity_loss(log_probs, msa_tokens, msa_mask, seq_mask, margin=0.1)\n",
        "print(f\"Baseline MSA loss: {baseline_loss.item():.4f}\")\n",
        "\n",
        "positions = torch.randn(B, L, 4, 3)\n",
        "X = positions + 0.1 * torch.randn_like(positions)\n",
        "mask = torch.ones(B, L)\n",
        "ca_loss = structure_consistency_loss(positions, X, mask)\n",
        "print(f\"CA loss: {ca_loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: ESM-based MSA similarity loss\n",
        "try:\n",
        "    import esm\n",
        "\n",
        "    model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "    model.eval()\n",
        "    token_map = torch.tensor([alphabet.get_idx(aa) for aa in 'ACDEFGHIKLMNPQRSTVWYX-'])\n",
        "    esm_loss = msa_similarity_loss_esm(\n",
        "        log_probs,\n",
        "        msa_tokens,\n",
        "        msa_mask,\n",
        "        seq_mask,\n",
        "        model,\n",
        "        token_map,\n",
        "        margin=0.1,\n",
        "    )\n",
        "    print(f\"ESM MSA loss: {esm_loss.item():.4f}\")\n",
        "except Exception as exc:\n",
        "    print(f\"ESM not available: {exc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: FAPE loss (requires OpenFold)\n",
        "try:\n",
        "    frames = torch.randn(1, B, L, 4, 4)\n",
        "    backbone_4x4 = torch.randn(B, L, 4, 4)\n",
        "    fape_loss = structure_fape_loss(frames, backbone_4x4, mask)\n",
        "    print(f\"FAPE loss: {fape_loss.item():.4f}\")\n",
        "except Exception as exc:\n",
        "    print(f\"OpenFold not available: {exc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a single batch, run the model, and evaluate losses\n",
        "try:\n",
        "    from training.utils import (\n",
        "        worker_init_fn,\n",
        "        loader_pdb,\n",
        "        build_training_clusters,\n",
        "        PDB_dataset,\n",
        "        StructureDataset,\n",
        "        StructureLoader,\n",
        "    )\n",
        "    from training.model_utils_struct import ProteinMPNN, featurize\n",
        "    import torch\n",
        "\n",
        "    data_path = 'my_path/pdb_2021aug02'  # update for your local data\n",
        "    params = {\n",
        "        'LIST': f'{data_path}/list.csv',\n",
        "        'VAL': f'{data_path}/valid_clusters.txt',\n",
        "        'TEST': f'{data_path}/test_clusters.txt',\n",
        "        'DIR': f'{data_path}',\n",
        "        'DATCUT': '2030-Jan-01',\n",
        "        'RESCUT': 3.5,\n",
        "        'HOMO': 0.70,\n",
        "    }\n",
        "\n",
        "    train, _, _ = build_training_clusters(params, debug=True)\n",
        "    train_set = PDB_dataset(list(train.keys()), loader_pdb, train, params)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=1, shuffle=True, worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    pdb_dict = next(iter(train_loader))\n",
        "    dataset = StructureDataset(pdb_dict, truncate=None, max_length=1000)\n",
        "    loader = StructureLoader(dataset, batch_size=1)\n",
        "    batch = next(iter(loader))\n",
        "\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model = ProteinMPNN(\n",
        "        node_features=128,\n",
        "        edge_features=128,\n",
        "        hidden_dim=128,\n",
        "        num_encoder_layers=3,\n",
        "        num_decoder_layers=3,\n",
        "        k_neighbors=48,\n",
        "        dropout=0.1,\n",
        "        augment_eps=0.2,\n",
        "        use_potts=True,\n",
        "        struct_predict=True,\n",
        "        struct_use_decoder_one_hot=True,\n",
        "    ).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    (\n",
        "        X,\n",
        "        S,\n",
        "        _,\n",
        "        mask,\n",
        "        lengths,\n",
        "        chain_M,\n",
        "        residue_idx,\n",
        "        mask_self,\n",
        "        chain_encoding_all,\n",
        "        _,\n",
        "        backbone_4x4,\n",
        "        _,\n",
        "    ) = featurize(\n",
        "        batch,\n",
        "        device,\n",
        "        augment_type='atomic',\n",
        "        augment_eps=0.2,\n",
        "        replicate=1,\n",
        "        epoch=0,\n",
        "        openfold_backbone=False,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_probs, etab_geom, e_idx, frames, positions, logits = model(\n",
        "            X,\n",
        "            S,\n",
        "            mask,\n",
        "            chain_M,\n",
        "            residue_idx,\n",
        "            chain_encoding_all,\n",
        "            return_logits=True,\n",
        "        )\n",
        "\n",
        "    loss_msa = msa_similarity_loss(log_probs, torch.randint(0, 22, (1, 2, log_probs.shape[1])), torch.ones(1, 2, log_probs.shape[1]), mask)\n",
        "    loss_struct = structure_consistency_loss(positions, X, mask)\n",
        "    print(f'Losses -> MSA: {loss_msa.item():.4f}, Struct: {loss_struct.item():.4f}')\n",
        "except Exception as exc:\n",
        "    print(f'Full model smoke test skipped: {exc}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}